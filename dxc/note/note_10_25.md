| case序号 | table name                  | 状态            | 注释                                                         | assign  |
| -------- | --------------------------- | --------------- | ------------------------------------------------------------ | ------- |
| 1        | ing_plrs_blk                | ok              | 复杂转换的例子                                               | lixiang |
| 2        | ing_plrs_bsn_ar_hrchy       |                 |                                                              | xiewang |
| 3        | ing_plrs_co_cd              | ok              |                                                              | roc     |
| 4        | ing_plrs_cst_cntr           | ok              | from_unixtime(unix_timestamp()) - > current_timestamp        | roc     |
| 5        | ing_plrs_ctry_hrchy         | review          | 201                                                          | roc     |
| 6        | ing_plrs_exch_rate          | review          | will check on 10/25 ，<br />to_date -> convert(datetime2(0), po_document_date) as [po_dcmt_dt]，还有几个函数没有转换过来 | roc     |
| 7        | ing_plrs_fnctl_ar_hrchy     |                 | （161、162、211 null函数有问题）211                          | roc     |
| 8        | ing_plrs_gl_accts           |                 |                                                              | xiewang |
| 9        | ing_plrs_inrn_ords          | ok              |                                                              | roc     |
| 10       | ing_plrs_mgmt_geo           | **review**， ok | if 参考 case when的写法，已完成。                            | roc     |
| 11       | ing_plrs_mru_hrchy          |                 |                                                              | roc     |
| 12       | ing_plrs_mru_lvl0           | ok              |                                                              | roc     |
| 13       | ing_plrs_mstr_coa           | ok              |                                                              | roc     |
| 14       | ing_plrs_pft_cntr_hrchy     | review          | 一些语句逻辑还需要改正10/28                                  | roc     |
| 15       | ing_plrs_wwas_athzn         | **review**，ok  | if 参考 case when的写法，以改完<br />10/26 多层if case 嵌套需要confirm | roc     |
| 16       | ing_plrs_wwas_athzn_bsn_cse | **review**，ok  | if 参考 case when的写法，以改完                              | roc     |

  

ing_plrs_mgmt_geo 改写if语句

```
if(geohierlvlcd='00',worldwidecd,subregion3cd) as subrgn_3_cd

case when geohierlvlcd='00' then worldwidecd else subregion3cd
end as [subrgn_3_cd]
```



sp_ing_plrs_wwas_athzn 改写

```
[if(action_code='A','Add',if(action_code='C','Change',if(action_code='D','Deactivated','0')))] as [acn_cd_dn]

case when action_code='A' then 'Add' when action_code='C' then 'Change' when action_code='D' then 'Deactivated' else '0' end as [acn_cd_dn]
```



sp_ing_plrs_exch_rate改写

```
ADD_MONTHS(convert(datetime2(0), CONCAT(effectivedate,'01')),01)

DATEADD(month, 01, CONVERT(VARCHAR(10),CONCAT(effectivedate,'01'), 12))
```

```
cast(accountingrate as decimal(20,4))*0.0001 as acctng_rate

CONVERT(DECIMAL(20,4), accountingrate)*0.0001
```



总结：

| 序号 | scala代码                                                    | sql代码                                                      |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1    | to_date(po_document_date, 'yyyyMMdd')                        | convert(datetime2(0), po_document_date)                      |
| 2    | from_unixtime(unix_timestamp())                              | current_timestamp                                            |
| 3    | if(split(ariba_id, '-')[1] is null, ariba_id,split(ariba_id, '-')[0]) as pr_nr | case when ariba_id like '%-%' then SUBSTRING(ariba_id, 0, charindex('-',ariba_id))<br/>	 else ariba_id<br/>end as [pr_nr] |
| 4    | ADD_MONTHS(to_date(CONCAT(effectivedate,'01'),'yyMMdd'),01) as prr_to_dt | DATEADD(month, 01, CONVERT(VARCHAR(10),CONCAT(effectivedate,'01'), 12)) |
| 5    | cast                                                         |                                                              |
| 6    | ADD_MONTHS(convert(datetime2(0), CONCAT(effectivedate,'01')),01) | DATEADD(month, 01, CONVERT(VARCHAR(10),CONCAT(effectivedate,'01'), 12)) |
| 7    | cast(accountingrate as decimal(20,4))*0.0001 as acctng_rate  | CONVERT(DECIMAL(20,4), accountingrate)*0.0001                |
|      | lit(null)                                                    | null                                                         |
|      | split                                                        | split                                                        |
|      | coalesce                                                     | coalesce                                                     |
|      | current_date()                                               | getdate()                                                    |
|      | concat_ws                                                    | concat_ws                                                    |
|      |                                                              |                                                              |

## spark function：

- split：Splits str around matches of the given pattern  [link](https://spark.apache.org/docs/3.2.0/api/scala/org/apache/spark/sql/functions$.html#split(str:org.apache.spark.sql.Column,pattern:String):org.apache.spark.sql.Column)

- withColumn:  Returns a new Dataset by adding a column or replacing the existing column that has the same name.  [link](https://spark.apache.org/docs/3.2.0/api/scala/org/apache/spark/sql/Dataset.html#withColumn(colName:String,col:org.apache.spark.sql.Column):org.apache.spark.sql.DataFrame)

  example:  [ref](https://sparkbyexamples.com/spark/spark-dataframe-withcolumn/)

  ```scala
  df.withColumn("Country", lit("USA"))  // to add a constant value to a DataFrame column
  ```

  ```scala
  df.withColumn("salary",col("salary")*100)  //to update the value of an existing column
  ```

- coalesce(e: [Column](https://spark.apache.org/docs/3.2.0/api/scala/org/apache/spark/sql/Column.html)*): [Column](https://spark.apache.org/docs/3.2.0/api/scala/org/apache/spark/sql/Column.html): Returns the first column that is not null, or null if all inputs are null. [Spark 3.2.0 ScalaDoc - org.apache.spark.sql.functions](https://spark.apache.org/docs/3.2.0/api/scala/org/apache/spark/sql/functions$.html#coalesce(e:org.apache.spark.sql.Column*):org.apache.spark.sql.Column)

- selectExpr: Selects a set of SQL expressions. This is a variant of `select` that accepts SQL expressions. [Spark 3.2.0 ScalaDoc - org.apache.spark.sql.Dataset](https://spark.apache.org/docs/3.2.0/api/scala/org/apache/spark/sql/Dataset.html#selectExpr(exprs:String*):org.apache.spark.sql.DataFrame)

- filter: Filters rows using the given SQL expression. [Spark 3.2.0 ScalaDoc - org.apache.spark.sql.Dataset](https://spark.apache.org/docs/3.2.0/api/scala/org/apache/spark/sql/Dataset.html#filter(conditionExpr:String):org.apache.spark.sql.Dataset[T])



## synapse function

- split : Splits a given string according to a given delimiter and returns a string array with the contained substrings.  [split() - Azure Data Explorer | Microsoft Docs](https://docs.microsoft.com/en-us/azure/data-explorer/kusto/query/splitfunction)





```sql
/* 当po_id列不包含'-'，就直接将po_id列选择出来，如果包含，就把到'-'前面的字符串取出来取出来
例子  'aaaa' return 'aaaa'
     'aa-aa' return 'aa'
*/
CASE WHEN CHARINDEX('-', po_id) < 1 THEN po_id ELSE SUBSTRING(po_id, 0, CHARINDEX('-', po_id)) END AS po_compare,
CASE WHEN CHARINDEX('-', po_id) < 1 THEN NULL ELSE SUBSTRING(po_id, CHARINDEX('-', po_id) + 1, LEN(po_id) - CHARINDEX('-', po_id)) END
```

date类型可以参照下面的页面

https://www.w3school.com.cn/sql/func_convert.asp
