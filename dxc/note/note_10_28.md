今天总结了一下前几天做的scala代码转sql代码。

转换的代码可以直接运行。

今天研究了下复杂代码的改写。相比于简单的代码，复杂的代码更多的是逻辑处理。

这个代码是sql server 转 synapse

join函数文档：[官方文档](https://spark.apache.org/docs/3.2.0/api/scala/org/apache/spark/sql/Dataset.html#join(right:org.apache.spark.sql.Dataset[_],joinExprs:org.apache.spark.sql.Column,joinType:String):org.apache.spark.sql.DataFrame)



首先是with as 中间不能有多个with

记录一下转换代码需要注意的问题。

### with as 用法

–针对一个别名
with tmp as (select * from tb_name)

–针对多个别名
with
  tmp as (select * from tb_name),
  tmp2 as (select * from tb_name2),
  tmp3 as (select * from tb_name3)

注意这里的最后一个as后面没有逗号。

问题一：

scala代码里面的list包含下面的两个字符转：这里有两种不同的0，上面的0是一个字符串类型，下面的0应该是int类型。

```
"'0' as inrn_ord_atr_10_tx"
"0 as recrd_clsfn_nr"
```

如果要把这两句转成sql的存储过程。是转成这个样子吗？

```
'0' as [inrn_ord_atr_10_tx],
'0' as [recrd_clsfn_nr],
```



/*
SUBSTRING(param1, param2, param3): param1 是要被切割的字符串. param2 是起始位置，param3是要切割的长度，返回切割后的字符串。
CHARINDEX(param1, param2, param3): param1 是匹配表达式， param2是目标字符串，param3是索引，默认是匹配第一个，返回第一个匹配的索引
example: split '1\\2\\3\\4\\5\\6'

L1 值为1，所以SUBSTRING的起始位置为0，长度为1： 
将起始位置直接设置为0， 
长度为CHARINDEX的返回值。这里的CHARINDEX('\\', PARENTLINEAGE_LIST)，表示首次匹配到'\\'的第一个\的索引。这里返回的是1。也就是返回匹配到\\时，前面有多少个字符。

L2 值为2， 所以起始位置为4，长度为1
将起始位置设置为L1的长度加3，长度设为
*/

```
WITH ref_df AS( SELECT
SUBSTRING(PARENTLINEAGE_LIST, 0, CHARINDEX('\\', PARENTLINEAGE_LIST)) AS [L1],
SUBSTRING(PARENTLINEAGE_LIST, LEN(L1)+3, CHARINDEX('\\', PARENTLINEAGE_LIST, 1) - LEN(L1)+2) AS [L2],
SUBSTRING(PARENTLINEAGE_LIST, LEN(L2)+3, CHARINDEX('\\', PARENTLINEAGE_LIST, 2) - LEN(L2)+2) AS [L3],
SUBSTRING(PARENTLINEAGE_LIST, LEN(L3)+3, CHARINDEX('\\', PARENTLINEAGE_LIST, 3) - LEN(L3)+2) AS [L4],
SUBSTRING(PARENTLINEAGE_LIST, LEN(L4)+3, CHARINDEX('\\', PARENTLINEAGE_LIST, 4) - LEN(L4)+2) AS [L5],
SUBSTRING(PARENTLINEAGE_LIST, LEN(L5)+3, CHARINDEX('\\', PARENTLINEAGE_LIST, 5) - LEN(L5)+2) AS [L6],
FROM imt_polaris_mru_heir AS P
WHERE P.MEMBERCLASS = "MRU" OR P.MEMBERCLASS = "FINMRU" OR P.MEMBERCLASS = "FINSubMRU"
)
```

