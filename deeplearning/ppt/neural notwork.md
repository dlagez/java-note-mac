## 2

神经网络：他的基本单位是神经元，通过神经元的连接组成各式各样不同的网络。他的诞生非常早，在1943年就已经提出了。他和我们现在非常热门的机器学习是没有什么交集的。只是后来神经网络被用作机器学习的模型。所以才和机器学习产生交集

深度学习：其实就是一个机器学习的问题。深度学习的模型通常比较复杂。也就是说从输入到输出他的链路比较长。要解决这样复杂的问题呢，它其实就是一个解决贡献度分配问题。就是每个模块对最终影响输出的贡献度是多少。就是你的变化对输出的影响比较大。你的贡献度就比较多。它其实是一个比较难的问题。

所以神经网络和深度学习其实两个不同的东西。现在深度学习主要的模型是神经网络。所以现在很多人会把它两等同在一起。其实他们是不一样的。在目前来看深度可以大约等于神经网络。我的方向主要是他们交集的部分。利用神经网络来解决深度学习的问题。

其实机器学习和神经网络可以这样理解, 比如说我要从数据库取数据这个问题, 这就是一个机器学习的问题, 我们可以使用很多的方法, 比如使用JDBC, 也可以使用mybatis, 还可以使用Spring DATA JPA, 这么多方法, 这些方法呢就相当于模型. Spring DATA JPA就相当于神经网络模型. 因为他的功能比较强大. 

我们其实有很多的模型, 比如决策树模型, 高斯混合模型, 支持向量机模型. 但是呢现在神经网络模型模型的功能比较强大, 模型的性能比较好, 所以我们选择神经网络模型.

## 3

### 知识结构：

深度学习是机器学习的一个部分。我们要了解深度学习先得了解机器学习。机器学习包含几个要素：模型、优化算法、学习准则。掌握了这些其实你对机器学习就有了大概得了解

机器学习还分了几个不同得类型：比如说监督学习、无监督学习，强化学习。

- 他们的难度是依次递增的, 监督模型比较简单, 比如说目标检测. 这个目标检测等会讲. 
- 然后就是无监督学习, 就是网络自己学习, 我们人不会干预他的学习过程, 所以他非常难以训练.
- 强化学习就不是我能去学习的问题了, 目前我连监督学习和无监督学习都还没掌握好.

先说监督学习：监督学习主要包括分类和回归这两大模型。我在入职前参加了一个数学建模得比赛。我把这个比赛得题目当作切入点把。

## 4

分类图

## 5

## 分类和回归

问题的描述, 这里先来了解几个专有名词.和一些概念

样本: 就是拥有的数据个数

特征: 每个样本所拥有的特征数

训练样本: 

预测样本: 

训练损失: 

预测损失: 

### 1、分类与回归是干嘛的？

不管是分类，还是回归，其本质是一样的，都是**对输入做出预测**，并且**都是监督学习**。说白了，就是根据特征，分析输入的内容，判断它的类别，或者预测其值。

### 2、二者有什么区别

重要要研究的就是两者的区别

### 1.输出不同

#### **1.分类问题输出的是物体所属的类别，回归问题输出的是物体的值。**

例如，最近福州天气比较怪（阴晴不定，像极了女朋友的脾气），为了能够对明天穿衣服的量以及是否携带雨具做判断，我们就要根据已有天气情况做预测。

上图中的天气可以分为：晴、阴、雨 三类，我们只知道今天（2019年3月26日）及之前的天气，我们会预测明天及以后几天的天气情况，如明天阴，下周一晴，这就是分类；

每一天的天气温度，我们知道今天及以前几天的温度，我们就要通过之前的温度来预测现在往后的温度，每一个时刻，我们都能预测出一个温度值，得到这个值用的方法就是回归。



只要分割先经过他们两个点的中间即可将他们分为两类. 所以我们可以作很多条分割线. 所以他的答案就有无数种.我们只需要选择其中一种即可. 因为他的样本量比较小, 所以我们不能区分这些方法的好坏. 但是如果们增加样本量. 情况就变得复杂起来了.

## 6

比如说我将样本量增加到10个. 他们在坐标系上的分布是这个样子的.

我们怎么拟合一个曲线(也叫一个函数)来进行分类. 将他们分成两类.

比如说我拟合了一条直线a, 这个直线a呢将所有的黑色的点都分为了一类, 将大部分的红色的点分为了一类, 但是呢有一个红色的点分错, 分到了黑色点的区域. 这在机器学习中叫做误差. 分错了就是有误差. 分错的点越多呢, 误差越大.

比如我在拟合一条曲线b, 这条绿色的线将红色的点和黑色点完全分开了. 红色和黑色的点都在线的一边. 

我们来比较一下我们拟合的这两个曲线, 或者叫方程的分类效果怎么样.

我们进行分类呢, 肯定是要进行预测的. 刚刚拟合的过程叫做训练, 使用训练样本来拟合一条曲线, 也就是从现有的样本中寻找他们分布的规律, 从而预测新样本的分类. 

## 分类的举例

就比如说, 狗和鸡的分类.我这里有一个狗和一个鸡. 他就是两个样本.

- 狗呢有他自己的特征, 狗有四条腿, 这是他的第一个特征. 狗还有牙齿.这是他的第二个特征.
- 鸡呢 只有两条腿, 而且鸡没有牙齿, 他只有喙.

所以我们根据狗和鸡的两个特征来将他们进行分类. 我这里把样本增加到十个, 对应刚刚的是个样本点. 

我们假设红色的点是狗, 黑色的点是鸡. 所以呢黑色的点是两条腿, 红色的点是四条腿.

但是呢我选去的这十个样本里面, 有个狗的腿受伤了, 他只有两条腿了. 对应的是在黑色点分布的红色的点.

- 所以我们拟合的**直线a**将只有两条腿的狗分类成了鸡. 这条直线a认为, 这个狗他不是狗 他是鸡.他分类错了, 所以呢他分类的有误差.
- **曲线b**将只有两条腿的狗也识别出来了. 所以他训练的误差比较小. 但是这样真的一定好吗.

其实曲线b将只有两条腿的狗也识别出来了, 这其实是不怎么好的. 因为他过拟合了. 什么是过拟合呢.就是就是这个拟合出来的曲线他过度的依赖了现有的样本, 这些现有的样本呢他是有一些特例的, 这些特例和我们通常的样本分布是有很大区别的. 就比如说拿刚才的狗来说. 我样本中有个两条腿的狗. 这个两条腿的狗呢和我们平时见到的狗长得并不相似, 就是有失一般性. 这就导致了一个问题. (然后去图上说明), 

曲线b会将鸡识别成狗, 因为肯定会有两条腿的鸡他的分布点会和两条腿的狗的分布点离的很近. 这就会增大预测的误差.

## 7

如果我们在每个样本中选择三个特征. 就相当于调高了维度, 在三维空间中拟合曲线.解法呢和上面的解法类似.

只不过解出来的函数更加的复杂.

就比如说我数学建模的题目。他是一个乳腺癌药物效果预测的题目. 叫预测药物对乳腺癌的治疗效果.

有一千八百条数据(药物)，每个药物有一百多个特征。这就相当于是在一百多维的空间函数拟合。这样的难度就已经算是特别的大了。我们使用的是神经网络来进行拟合的.

回归并不只是需要考虑如何将他们拟合的更好。还要考虑自变量之间关系。比如自变量之间的影响, 

比如房价的回归, 我们需要预测某个地段的房价. 房子的入住率和周边配套设施会影响房价, 但是入住率也会影响周边的配套设施, 如果你的入住率比较小, 人都没有几个, 就肯定没有很多的商家进行投资来建设周边的设施, 从而也会影响房价. 所以呢房价的预测, 也就是回归他是以很复杂的问题. 有很多的因素需要考虑到.不仅仅只是拿着一些数据直接进行回归分析.

我这个建模的题目也需要考虑自变量之间的关系.



## 8

回归问题, 回归问题就是使用已有的特征来进行函数的拟合, 这个函数和上面的分类函数本质上是一样的.

就是我们使用样本的特征, 既可以给样本进行分类, 也可以给样本进行回归分析.

只是他们的输出不同, 分类的输出是离散的, 回归的输出是连续的.

## 9

训练样本和测试样本.

## 10,11

这里就不深入了, 了解完分类和回归之后, 更加复杂的分类和回归问题使用简单的线性回归就不行了, 就需要更加复杂的神经网络来解决他们了.

现在我们一起来一起了解一下人工智能.



## 梯度下降



