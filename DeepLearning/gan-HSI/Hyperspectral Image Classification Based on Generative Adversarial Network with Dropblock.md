### ABSTRACT

深度学习（DL）算法广泛应用于高光谱图像分类。然而，空间语义信息利用不足和HSIs样本数量不足都限制了基于DL的HSIs算法的分类性能。在本文中，我们提出了一种基于DropBlock结构的生成对抗网络（GAN）的新方法。具体地说，DropBlock通过删除特征映射的连续区域来强制卷积神经网络（CNN）中的每个单元学习特征，因此更多的空间语义信息能够有助于HSIs分类。此外，GAN模型可以通过对抗性博弈生成真实样本，以缓解HSIs数据短缺的问题。大量的实验比较证明了该方法的有效性。 

### INTRODUCTION

高光谱图像（HSI）包含丰富的光谱信息和空间信息，特别有利于区分观测区域内的各种物质[1][2]。HSIs分类作为高光谱遥感的一个重要应用，近年来得到了广泛的研究[3][4][5]。在提出的分类算法中，深度学习（DL）方法受到了广泛关注[6][7][8]。DL算法不使用手工特征，而是采用卷积神经网络（CNN）自动提取各种光谱和空间特征来辅助分类。虽然这些DL算法取得了可接受的分类性能，但它们的效果仍然受到两个主要缺点的限制：空间语义信息的利用不足和HSIs样本数量有限。

首先，传统的DL方法仅使用固定的邻域区域，无法有效地利用空间语义信息。例如，[6]中的作者采用K*K邻域作为中心像素，然后将其提供给CNN。通过这种方法，单个邻域区域中的空间语义信息对分类过程的贡献是有限的。换句话说，不能保证邻域中每个部分的连续空间语义信息能够被充分学习和使用。此外，CNN接收来自不同K*K区域的大量重叠区域作为输入，并提取大量相同的空间语义特征，这些特征冗余将严重影响网络的有效性。 

其次，可用于培训的标记HSIs数据不足。通常，DL算法在训练中需要大量的数据。然而，收集和标记HSIs数据是困难、昂贵和耗时的。在这种情况下，会出现严重的过拟合现象，从而导致测试性能下降[9]。 

为了在分类中充分利用空间语义信息，我们利用DropBlock结构来辅助CNN[10]。DropBlock是Ghiasi提出的一种新的DL方法，可以利用语义信息。DropBlock作用于隐藏层的特征映射，以便将特征映射的随机连续区域中的单元放在一起。这些网络将充分利用剩余的语义信息，并通过随机删除一些单元，迫使它们提取不同的特征进行分类。基于此，在HSIs分类问题中使用DropBlock是一种相当有效的方法。 

为了在分类中充分利用空间语义信息，我们利用DropBlock结构来辅助CNN[10]。DropBlock是Ghiasi提出的一种新的DL方法，可以利用语义信息。DropBlock作用于隐藏层的特征映射，以便将特征映射的随机连续区域中的单元放在一起。这些网络将充分利用剩余的语义信息，并通过随机删除一些单元，迫使它们提取不同的特征进行分类。基于此，在HSIs分类问题中使用DropBlock是一种相当有效的方法。 

在本文中，我们提出了一种新的基于GAN的DropBlock算法（DBGAN），用于HSI分类。DropBlock应用于重叠区域和不同未阻塞单元的空间语义信息利用。同时，利用GAN模型生成HSIs图像，可以明显扩展样本集。我们证明，与其他相关分类器相比，我们的模型可以在多个常用数据集上提供显著改进的分类性能。 

论文的其余部分组织如下。在第2节中，我们介绍了我们的算法，包括HSI的DropBlock和我们模型的结构。第3节详细介绍了实验结果。结论和讨论见第4节。 

###  METHOD

本节介绍拟议的DBGAN。我们将分别介绍HSI的DropBlock和DBGAN的结构。

DropBlock for HSIs

空间语义信息在HSI分类中发挥着重要作用，并已用于基于DL的HSI算法.中心像素的`K * K`邻域是利用`(employ)`空间语义信息的一种常见而有效的方法。然而，根据之前的分析，邻里地区的空间语义信息没有得到充分利用。因此，我们采用DropBlock结构来保证空间语义信息可以在HSI分类中生效。

DropBlock通过从隐藏层中删除特征图中单元的连续区域来工作，因此，可以删除一些特定的语义信息，并强制执行剩余单元进行分类。图一演示了随机下降与DropBlock之间的比较，随机下降在特征地图上随机下降离散单位。如图所示，与DropBlock结构中连续区域的删除相比，随机删除离散单元将破坏包含密切相关信息的附近单元之间的关系。在DropBlock的过程中，首先对掩码M进行特征图的采样，M中的每个元素M i、j都以Bernoulli为主题分布，然后零蛋白M被消耗到一个零区域。在DropBlock中有两个重要的参数。Block_size是要被删除区域的大小，y控制多少单元需要被删除。我们可以通过y获得M。

和y可以按单位保留的比例计算



DropBlock在HSIs分类中的优势可以总结如下：

首先，通过DropBlock的应用，邻域区域的大部分空间语义信息可以在测试过程中得到集中和决策，而不是主要决定中心像素最终类别的有限部分。图2显示了DropBlock结构的原理。当我们使用DropBlock结构在训练过程的每个阶段删除一些空间语义信息时，其余单元将强制执行以影响训练。与此同时，在图2中也值得注意的是，由于DropBlock的掩码M在训练过程中不断变化而不是固定的原因，删除的信息没有丢失。此外，在不同的培训时代，M受制于新的Bernoulli分布，因此剩余的功能单元完全不同。按照这种方法，空间语义信息不仅被保留，而且被充分学习和使用。



其次，DropBlock 可以解决 HSI 分类中相同的特征冗余，增加特征的多样性。 由于大多数可用的 HSI 数据具有较低的图像空间尺寸，更重要的是采用 `K * K` 邻域区域的空间相关性利用方法，不同中心像素的邻域区域之间出现了严重的重叠现象。 如图 3 所示，在卷积层中，从重叠区域提取的空间语义特征是相同的。 因此，大量冗余特征将显着影响网络效率。 然而，通过在不同的特征图中随机丢弃单元块，DropBlock 可以通过分析重叠区域中唯一的未阻塞剩余单元来提取完全不同的空间语义特征。 这样可以减少特征冗余，同时增加空间特征的多样性。