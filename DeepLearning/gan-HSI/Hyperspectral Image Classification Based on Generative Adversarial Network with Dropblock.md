### ABSTRACT

深度学习（DL）算法广泛应用于高光谱图像分类。然而，空间语义信息利用不足和HSIs样本数量不足都限制了基于DL的HSIs算法的分类性能。在本文中，我们提出了一种基于DropBlock结构的生成对抗网络（GAN）的新方法。具体地说，DropBlock通过删除特征映射的连续区域来强制卷积神经网络（CNN）中的每个单元学习特征，因此更多的空间语义信息能够有助于HSIs分类。此外，GAN模型可以通过对抗性博弈生成真实样本，以缓解HSIs数据短缺的问题。大量的实验比较证明了该方法的有效性。 

### INTRODUCTION

高光谱图像（HSI）包含丰富的光谱信息和空间信息，特别有利于区分观测区域内的各种物质[1][2]。HSIs分类作为高光谱遥感的一个重要应用，近年来得到了广泛的研究[3][4][5]。在提出的分类算法中，深度学习（DL）方法受到了广泛关注[6][7][8]。DL算法不使用手工特征，而是采用卷积神经网络（CNN）自动提取各种光谱和空间特征来辅助分类。虽然这些DL算法取得了可接受的分类性能，但它们的效果仍然受到两个主要缺点的限制：空间语义信息的利用不足和HSIs样本数量有限。

首先，传统的DL方法仅使用固定的邻域区域，无法有效地利用空间语义信息。例如，[6]中的作者采用K*K邻域作为中心像素，然后将其提供给CNN。通过这种方法，单个邻域区域中的空间语义信息对分类过程的贡献是有限的。换句话说，不能保证邻域中每个部分的连续空间语义信息能够被充分学习和使用。此外，CNN接收来自不同K*K区域的大量重叠区域作为输入，并提取大量相同的空间语义特征，这些特征冗余将严重影响网络的有效性。 

其次，可用于培训的标记HSIs数据不足。通常，DL算法在训练中需要大量的数据。然而，收集和标记HSIs数据是困难、昂贵和耗时的。在这种情况下，会出现严重的过拟合现象，从而导致测试性能下降[9]。 

为了在分类中充分利用空间语义信息，我们利用DropBlock结构来辅助CNN[10]。DropBlock是Ghiasi提出的一种新的DL方法，可以利用语义信息。DropBlock作用于隐藏层的特征映射，以便将特征映射的随机连续区域中的单元放在一起。这些网络将充分利用剩余的语义信息，并通过随机删除一些单元，迫使它们提取不同的特征进行分类。基于此，在HSIs分类问题中使用DropBlock是一种相当有效的方法。 

为了在分类中充分利用空间语义信息，我们利用DropBlock结构来辅助CNN[10]。DropBlock是Ghiasi提出的一种新的DL方法，可以利用语义信息。DropBlock作用于隐藏层的特征映射，以便将特征映射的随机连续区域中的单元放在一起。这些网络将充分利用剩余的语义信息，并通过随机删除一些单元，迫使它们提取不同的特征进行分类。基于此，在HSIs分类问题中使用DropBlock是一种相当有效的方法。 

在本文中，我们提出了一种新的基于GAN的DropBlock算法（DBGAN），用于HSI分类。DropBlock应用于重叠区域和不同未阻塞单元的空间语义信息利用。同时，利用GAN模型生成HSIs图像，可以明显扩展样本集。我们证明，与其他相关分类器相比，我们的模型可以在多个常用数据集上提供显著改进的分类性能。 

论文的其余部分组织如下。在第2节中，我们介绍了我们的算法，包括HSI的DropBlock和我们模型的结构。第3节详细介绍了实验结果。结论和讨论见第4节。 

###  METHOD

DropBlock for HSIs

空间语义信息在HSIs分类中起着重要作用，并已被用于基于DL的HSIs算法中。K K  中心像素邻域是利用空间语义信息的一种常用而有效的方法。然而，基于前面的分析，邻域区域的空间语义信息并没有得到充分利用。因此，我们采用DropBlock结构来保证空间语义信息在HSIs分类中的有效性。 



DropBlock的工作原理是将特征图中的连续单元区域从隐藏层中删除，因此，可以删除某些特定的语义信息，并强制执行剩余单元以有效地进行分类。图1展示了在特征图上随机丢弃离散单元的随机丢弃和丢弃块之间的比较。如图所示，与DropBlock结构中删除连续区域相比，随机删除离散单元将破坏包含密切相关信息的相邻单元之间的关系。在DropBlock过程中，首先对特征映射的掩码M进行采样，每个元素i  jM In M服从伯努利分布，然后将M中的零扩展为零块。DropBlock有两个重要参数，_BlockSize是要删除的块的大小，以及  控制要放下多少个单位。我们可以通过: 



DropBlock在HSIs分类中的优势可以总结如下。首先，通过DropBlock的应用，邻域中的大部分空间语义信息可以在测试过程中被聚焦并做出决策，而不是主要决定中心像素最终类别的有限部分。图2显示了DropBlock结构的原理。当我们在训练过程的每个阶段使用DropBlock结构去除一些空间语义信息时，剩余的单元将被强制执行以影响训练。同时，在图2中还值得注意的是，由于用于DropBlock的掩码M在训练过程中不断变化而不是固定不变，因此丢弃的信息没有丢失。此外，在不同的训练时期，M服从新的伯努利分布，因此剩余的功能单元完全不同。通过这种方法，不仅可以保留空间语义信息，还可以充分学习和使用空间语义信息。

其次，DropBlock可以解决HSIs分类中相同的特征冗余，增加特征的多样性。由于大多数可用HSIs数据的低图像空间大小，更重要的是空间分辨率 基于K的相关利用方法  邻域区域，不同中心像素的邻域区域之间存在严重的重叠现象。如图3所示，在卷积层中，从重叠区域提取的空间语义特征是相同的。因此，大量冗余功能将显著影响网络效率。然而，通过在不同的特征图中随机删除单元块，DropBlock可以通过分析重叠区域中唯一的未阻塞剩余单元来提取完全不同的空间语义特征。这样既减少了特征冗余，又增加了空间特征的多样性

DropBlock generative adversarial networks

GAN是一个新的深度学习框架，它使用极大极小博弈训练深度生成模型。为了学习与真实数据分布相匹配的生成分布，对GAN的两个子模型——生成器和鉴别器进行了对抗性训练。生成器通过将噪声变量转换为样本，从生成分布生成样本，而鉴别器旨在区分样本与真实数据分布和生成分布。随着训练过程的继续，生成器的生成能力和鉴别器的辨别能力都在不断增强。最后，生成器将输出真实样本，鉴别器将无法区分生成数据和真实数据。 

受GAN的启发，我们设计了一个DropBlock  GAN（DBGAN），它在基于GAN的端到端HSIs分类模型中设置DropBlock结构。DBGAN生成器提供大量生成的HSIs图像用于数据扩充，DropBlock结构可以帮助鉴别器充分利用空间语义信息。DBGAN的数据扩充方法缓解了训练中的过度拟合现象，与旋转、平移、缩放等传统数据扩充技术相比是一种完全不同的策略。发生器和鉴别器都是从CNN修改而来的。如表所示。1.生成器包含完全连接层、卷积层和上采样层，而鉴别器仅包含完全连接层和卷积层。值得注意的是，具有大感受野的深层单元在分类时会丢失太多信息，因此在前三个浅卷积之后设置了DropBlock（DB）结构 我们将_blocksize和_keepprob分别设置为3和0.85。基于端到端GAN模型和DropBlock结构，分类性能可以大幅提升。 



图4显示了DBGAN的框架，为了加快训练和稳定DBGAN模型，我们使用PCA将整个HSI压缩到合适的维度。生成器接收随机噪声（）z  作为输入生成假邻域，鉴别器结合生成的假邻域作为输入得到真实邻域。卷积层利用DropBlock结构提取特征，最后将特征反馈到最后一层进行分类。最后一层不再是仅仅区分样本是真是假的二元分类器，本文采用了K+1分类器，其中K是真类，另一个类别是假类。损失函数包括两部分，其中realL由邻域数据（，）x  y之间的交叉熵获得 训练集及其预测的课堂模式（，）el x y , fakeL是根据真实的邻域（）数据x设计的  伪邻域（）gz分为K个实类和伪类。基于这些，损失函数变为： 