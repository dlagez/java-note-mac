### 论文：

### abstract

我们研究了条件对抗网络作为图像到图像翻译问题的通用解决方案。这些网络不仅学习从输入图像到输出图像的映射，还学习训练此映射的丢失函数。这使得对传统上需要非常不同的损失公式的问题采用相同的通用方法成为可能。我们演示了这种方法在合成标签地图上的照片、从边缘地图重建物体和给图像着色等方面是有效的。事实上，自与该论文相关的pix2pix软件发布以来，大量互联网用户（其中许多是艺术家）发布了他们自己的系统实验，进一步证明了其广泛的适用性和易于采用性，而无需参数调整。作为一个社区，我们不再手工设计我们的映射函数，这项工作表明，我们也可以在不手动工程损失函数的情况下实现合理的结果。

### Introduction

In analogy to automatic language translation, we define automatic *image-to-image translation* as the task of translating one possible representation of a scene into another。

given sufficient training data (see Figure 1). Traditionally, each of these tasks has been tackled with separate, special-purpose machinery

在传统的方法上，每种类型的图像转换都需要特定类型的转换器，也就是一个转换模型。但是这篇文章推出了一个模型，使用这种模型可以完成所有的图像转换任务。



尽管这些学习过程是自动的，设计有效的损失任然需要大量人工。换而言之，我们任然需要去告诉CNN我们希望去最小化什么。但是我们必须小心我们所希望的，



如果我们采取天真的方法，要求CNN尽量减少预测和地面真相像素之间的欧几里得距离，它往往会产生模糊的结果

这是因为欧几里得距离通过平均所有可信的输出最小化，这会导致模糊。提出迫使CNN做我们真正想做的事情的损失函数——例如，输出清晰、逼真的图像——是一个悬而未决的问题，通常需要专业知识。

相反，如果我们只能指定一个高级目标，如“使输出无法与现实区分开”，然后自动学习适合满足此目标的损失功能，那将是非常可取的。幸运的是，这正是最近提议的生成对抗网络（GAN）所做的

#### important

 GANs学习一种损失，试图对输出图像进行真实还是假的分类，同时训练生成模型以尽量减少这种损失。模糊的图像是不能容忍的，因为它们看起来显然是假的。由于GAN学习的损失适应了数据，它们可以应用于许多传统上需要非常不同类型丢失函数的任务。



本文探讨了条件设置中的GANss。正如GAN学习数据的生成模型一样，condi-tional GANs（cGANs）学习条件生成模型[24]。这使得cGAN适合图像到图像的转换任务，我们以输入图像为条件，并生成相应的输出图像。



在过去的两年里，GAN得到了大力研究，我们在本pa-per中探索的许多技术之前都提出了。尽管如此，更早的论文专注于特定应用，目前还不清楚图像条件GAN作为图像到图像翻译的通用解决方案有多有效。我们的主要贡献是示范战略，在各种各样的问题上，有条件GAN会产生合理的结果。我们的第二个贡献是提出一个足以取得良好效果的简单框架，并分析所有重要结构选择的效果。代码可在

### Related work

图像建模的结构化损耗 图像到图像的翻译问题通常表述为每像素的校正或回归，这些公式将输出空间视为“非结构化”，即给定输入图像，每个输出像素都被视为有条件地依赖于所有其他像素，相反，Condi-tional GANs学习结构化损失。结构化损失会惩罚产出的联合配置。

大量文献考虑过此类损失，其方法包括条件随机字段[10]、SSIM指标[56]、特征匹配[15]、非参数损失[37]、卷积伪前[57]和基于匹配协方差统计的损失[30]。可选GAN的不同之处在于损失是学到的，理论上可以惩罚产出和目标之间任何可能的结构。



条件GAN 我们不是第一个在条件设置中应用GAN的人。先前和并发的作品以离散标签[41、23、13]、文本[46]以及图像为GAN提供了条件。

图像条件模型处理了来自普通地图的图像预测[55]、未来帧预测[40]、产品照片生成[59]和稀疏注释[31、48]的图像生成（参考[47]用于对同一问题的自回归方法）。

一些其他论文也使用GAN进行图像到图像的映射，但只无条件地应用GAN，重新基于其他术语（如L2回归），以迫使输出以输入为条件。这些论文在绘画[43]、未来状态预测[64]、用户压力引导的图像操作[65]、样式传输[38]和超分辨率[36]方面取得了令人印象深刻的结果。每一种方法都是为特定的推广量身定制的。我们的框架不同之处在于，没有什么是针对应用程序的。这使得我们的设置比大多数其他设置都要简单得多。



我们的方法在发电机和鉴别器的几种架构选择上也与之前的工作不同。与过去的工作不同，对于我们的生成器，我们使用基于“U-Net”的体系结构[50]，对于我们的鉴别器，我们使用convo-lutional“PatchGAN”分类器，它只惩罚图像补丁规模上的结构。[38] 曾提出类似的 PatchGAN ar- chitecture，以获取当地风格统计数据。在这里，我们表明这种方法对更广泛的问题有效，并调查了更改补丁大小的影响。



### Method

GAN是从随机噪声矢量z到输出图像y的生成模型，相比之下，条件GAN从观测到的图像x和随机噪声矢量z到y，G：{x，z}→y学习映射。生成器G受过训练，可以产生无法由受敌对训练的鉴别器D区分的输出与“真实”图像，D受过训练，可以尽可能地检测生成器的“假图”。这个训练程序如图2所示。



### Objective

<img src="https://cdn.jsdelivr.net/gh/dlagez/img@master/image-20220225155114201.png" alt="image-20220225155114201" style="zoom:50%;" />

以前的方法发现，将GAN目标与更传统的损失（如L2差异）相结合是有益的[43]。鉴别器的工作保持不变，但生成器的任务不仅要愚弄鉴别器，还要接近L2意义上的地面真相输出。我们还探索了这个选项，使用L1距离而不是L2，因为L1鼓励减少模糊性：



没有z，网络仍然可以学习从x到y的映射，但会产生确定性输出，因此无法匹配三角洲函数以外的任何分布。过去的条件GAN已经承认了这一点，除了x（例如[55]）外，还提供了高斯噪声z作为生成器的输入。在最初的实验中，我们发现这种策略无效——生成器只是学会了忽略噪音——这与Mathieu等人一致



相反，对于我们的最终模型，我们只以中断的形式提供噪音，在训练和测试时都应用于发电机的几层。尽管有掉落噪音，但我们只观察到蚊帐输出的微小随机性。设计产生高度随机输出的条件GAN，从而捕获它们建模的条件分布的全熵，是当前工作悬而未决的一个重要问题。



### Network architectures

convolution-BatchNorm-ReLu 都是这个形式的。

### Generator with skips

图像到图像翻译问题的一个定义特征是，它们将高分辨率输入网格映射到高分辨率输出网格。此外，对于我们考虑的问题，输入和输出在表面外观上有所不同，但两者都是相同底层结构的渲染。因此，输入中的结构与输出中的结构大致对齐。我们围绕这些考虑因素设计发电机架构。



以前许多解决该领域问题的解决方案[43、55、30、64、59]都使用了编码器-解码器网络[26]。在这样一个网络中，输入通过一系列逐步下采样的铺设器传递，直到瓶颈层，此时过程被逆转。这种网络要求所有信息流通过所有层，包括瓶颈。对于许多图像翻译问题，输入和输出之间共享了大量低级信息，最好将这些信息直接通过网络穿梭。例如，在图像着色的情况下，输入和输出共享突出边缘的位置。



为了给发电机一种绕过瓶颈获取此类信息的方法，我们添加了跳过连接，降低了“U-Net”的一般形状[50]。具体而言，我们在每个层i和n-i层之间添加跳过连接，其中n是层总数。每个跳过连接只是将i层的所有通道与n-i层的所有通道连接起来。

#### 理解：

增加跳跃层是为了解决这个问题：对于许多的图像转化问题，输入和输出之间共享了大量低级信息，增加跳跃层就解决了这些问题，这些信息可以直接通过网络穿梭。例如，在图像着色的情况下，输入和输出共享突出边缘的位置。



### Markovian discriminator

It is well known that the L2 loss – and L1，produces blurry results on image generation problems

尽管这些损失不能产生高频率的清晰度。然而，在许多情况下，它们以快的速度捕捉低频。对于出现这种情况的问题，我们不需要一个全新的框架来在低频下强制正确性。L1已经可以了。



这促使GAN鉴别器仅限于建模高频结构，依靠L1项来强制低频正确性（Eqn.4）。为了建模高频，只需限制我们对本地图像补丁结构的关注即可。因此，我们设计了一个判别器架构——我们称之为PatchGAN——它只惩罚补丁规模的结构。这个鉴别器试图对im-年龄段的每个N×N补丁进行分类是真实的还是假的。我们在图像上运行这个判别器卷积盟友，平均所有响应以提供D的最终输出。



在第4.4节中，我们证明N可以比图像的全尺寸小得多，并且仍然可以产生高质量的结果。这是有利的，因为较小的PatchGAN参数更少，运行速度更快，并且可以应用于任意大的图像。



### 代码：

github连接：[link](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)

首先看一下模型吧

```

```

